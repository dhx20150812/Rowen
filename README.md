# Retrieve Only When It Needs: Adaptive Retrieval Augmentation for Hallucination Mitigation in Large Language Models

## About Rowen
Rowen is a novel method that meticulously integrate the parametric knowledge within LLMs with external information for hallucination mitigation. Rowen introduces an innovative multilingual semantic-aware hallucination detection module that perturbs semantically equivalent questions and then evaluates the semantic consistency of various responses across diverse languages when subjected to these perturbed queries. Instances where LLMs exhibit inconsistencies in their responses to a specific question, are flagged as potential cases of internal hallucination. In such scenarios, a retrieval-augmented generation process is activated to fetch relevant information, thereby assisting LLMs in refining their reasoning chains and rectifying potential hallucinations. If the perturbed answers consistently convey accurate content, the original answer generated by the internal reasoning is directly adopted.

## Requirements
- openai == 0.28.0
- [Serper Api Key](https://serper.dev/)
- [OpenAI Api Key](https://chat.openai.com)

## Usage
1. Run experiments on the TruthfulQA dataset

```bash
python run_truthfulqa.py
```

2. Run experiments on the StrategyQA dataset

```bash
python run_strategyqa.py
```

Generated responses and evaluation results will be saved automatically.

Please be careful, the experiments are relatively expensive because Rowen calls OpenAI API multiple times for a single question. You can decrease the `k` (number of pertubed questions) in the file to reduce the cost.

## Performance
![Main Result of Rowen](fig/main_results.png)
